# Dockerfile for NVIDIA GPU (CUDA)
FROM nvidia/cuda:12.6.0-runtime-ubuntu22.04

WORKDIR /app

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    python3.12 \
    python3-pip \
    python3.12-venv \
    git \
    wget \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# 创建符号链接
RUN ln -sf /usr/bin/python3.12 /usr/bin/python && \
    ln -sf /usr/bin/python3.12 /usr/bin/python3

# 升级 pip
RUN python -m pip install --upgrade pip

# 复制依赖文件
COPY requirements.txt* ./
COPY environment.yml* ./

# 安装 Python 依赖
RUN pip install --no-cache-dir \
    numpy \
    tqdm \
    loguru \
    click \
    pillow \
    opencv-python-headless \
    PyQt6 \
    transformers \
    iopaint \
    pyyaml \
    psutil

# 安装 PyTorch (CUDA 版本)
RUN pip install --no-cache-dir \
    torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu124

# 复制应用代码
COPY *.py ./
COPY *.yml ./
COPY *.md ./

# 下载 LaMA 模型
RUN iopaint download --model lama

# 创建目录
RUN mkdir -p /app/input /app/output

# 设置环境变量
ENV QT_QPA_PLATFORM=offscreen
ENV DISPLAY=:99

EXPOSE 8080

CMD ["python", "remwm.py", "--help"]
